{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "# from plotly_wordcloud import plotly_wordcloud\n",
    "from geopy.geocoders import Nominatim\n",
    "import folium\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import defaultdict\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import re\n",
    "# from jupyter_dash import JupyterDash\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "# This ensures Plotly output works in multiple places:\n",
    "# In VSCode and also nbconvert from jupyter notebook to HTML\n",
    "# See https://plotly.com/python/renderers/#multiple-renderers\n",
    "pio.renderers.default = \"svg\"\n",
    "\n",
    "png_renderer = pio.renderers[\"png\"]\n",
    "png_renderer.width = 1000\n",
    "png_renderer.height = 600\n",
    "\n",
    "# Set SVG renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Dropdown Menu Button Styling \n",
    "default_bar_dropdown_styling = dict(\n",
    "    bgcolor=\"white\",\n",
    "    active=0,\n",
    "    yanchor='top',\n",
    "    xanchor='center',\n",
    "    direction='up',\n",
    "    y=-0.1,\n",
    "    x=0.5,\n",
    ")\n",
    "\n",
    "# default_table_dropdown_styling = dict(\n",
    "#     bgcolor=\"white\",\n",
    "#     active=0,\n",
    "#     yanchor='top',\n",
    "#     xanchor='center',\n",
    "#     direction='down',\n",
    "#     y=1.3,\n",
    "#     x=0,\n",
    "# )\n",
    "\n",
    "# MACROS used for calculation of table height\n",
    "TABLE_CELL_HEIGHT_DEFAULT = 25\n",
    "TABLE_CELL_PADDING = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly Custom Template\n",
    "bnw = go.layout.Template(\n",
    "    layout=go.Layout(\n",
    "        xaxis=go.layout.XAxis(\n",
    "            showline=True,\n",
    "            linecolor=\"black\",\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            title=\"\"\n",
    "        ),\n",
    "        margin=go.layout.Margin(\n",
    "            l=2,\n",
    "            r=2\n",
    "        ),\n",
    "        yaxis=go.layout.YAxis(\n",
    "            showline=True,\n",
    "            linecolor=\"black\",\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            title=\"\"\n",
    "        ),\n",
    "        font=dict(color=\"#4f4f4f\", size=15),\n",
    "        title=go.layout.Title(\n",
    "            font=go.layout.title.Font(\n",
    "            #     # family=\"Old Standard TT\",\n",
    "                size=19\n",
    "            ),\n",
    "            # ),\n",
    "        ),\n",
    "        legend=go.layout.Legend(\n",
    "            font=go.layout.legend.Font(\n",
    "                size=17\n",
    "            )\n",
    "        ),\n",
    "        paper_bgcolor=\"#D0E3F1\",\n",
    "        dragmode=\"pan\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "\n",
    "    # Does not work for hovertemplate\n",
    "    # data=dict(\n",
    "    #     bar=[go.Bar(hovertemplate=\"<b>%{label}</b><br><i>Count</i>: %{value}\")],\n",
    "    #     scatter=[go.Scatter(hovertemplate=\"<b>%{label}</b><br><i>Count</i>: %{value}\")],\n",
    "    #     pie=[go.Pie(hovertemplate=\"<b>%{label}</b><br><i>Count</i>: %{value}\")],\n",
    "    #     histogram=[go.Histogram(hovertemplate=\"<b>%{label}</b><br><i>Count</i>: %{value}\")]\n",
    "    # )\n",
    ")\n",
    "\n",
    "pio.templates[\"bnw\"] = bnw\n",
    "\n",
    "# Combine custom template with seaborn\n",
    "px.defaults.template = \"seaborn+bnw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_cringe_hovertext_template = dict(\n",
    "    bar=dict(hovertemplate=\"<b>%{x}</b><br><i>Count</i>: %{y}\"),\n",
    "    scatter=dict(hovertemplate=\"<b>%{x}</b><br><i>Count</i>: %{y}\"),\n",
    "    pie=dict(hovertemplate=\"<b>%{label}</b><br><i>Count</i>: %{value}\"),\n",
    "    histogram=dict(hovertemplate=\"<b>%{x}</b><br><i>Count</i>: %{y}\"),\n",
    "    histogram_h=dict(hovertemplate=\"<b>%{y}</b><br><i>Count</i>: %{x}\") # histogram_horizontal\n",
    ")\n",
    "\n",
    "no_scroll_zoom_config = dict(\n",
    "    scrollZoom=False\n",
    ") \n",
    "\n",
    "static_plot_config = dict(\n",
    "    staticPlot=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_checker(a: pd.Series, check_unique=False, check_null=True):\n",
    "    '''\n",
    "        Set check_unique=True to check for unique values for a specifically column.\n",
    "        Number of nulls is checked automatically.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        ug157#   a = pd.DataFrame([[1], [2], [2]], columns=[\"A\"])\n",
    "        ug157#   data_checker(a[\"A\"], check_unique=True)\n",
    "\n",
    "        Out:  \n",
    "        Unique values [1 2]\n",
    "        Number of NA Values: 0\n",
    "    '''\n",
    "    if check_unique:\n",
    "        if a.dtype == np.float64:\n",
    "            print(\"Unique values\", a.sort_values().unique())\n",
    "        else:     \n",
    "            print(\"Unique values\", a.sort_values(key=lambda x: x.str.lower()).unique())\n",
    "    \n",
    "    if check_null:\n",
    "        print(\"Number of NA Values:\", int(a.isnull().sum()))\n",
    "\n",
    "# a = pd.DataFrame([[1], [2], [2]], columns=[\"A\"])\n",
    "# data_checker(a[\"A\"], check_unique=True)\n",
    "\n",
    "def calc_table_height(a, base=208, height_per_row=25, char_limit=30, height_padding=16.5):\n",
    "    '''\n",
    "    a: The dataframe with only the columns you want to plot\n",
    "    base: The base height of the table (header without any rows)\n",
    "    height_per_row: The height that one row requires\n",
    "    char_limit: If the length of a value crosses this limit, the row's height needs to be expanded to fit the value\n",
    "    height_padding: Extra height in a row when a length of value exceeds char_limit\n",
    "\n",
    "    Source: https://stackoverflow.com/questions/48223370/python-plotly-autosize-table-plot\n",
    "    '''\n",
    "    total_height = 0 + base\n",
    "    for x in range(a.shape[0]):\n",
    "        total_height += height_per_row\n",
    "        for y in range(a.shape[1]):\n",
    "            if len(str(a.iloc[x][y])) > char_limit:\n",
    "                total_height += height_padding\n",
    "                break\n",
    "    return total_height\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sample_size_annotation_for_figure(fig, df_new, x_anchor=\"right\", y_anchor=\"bottom\", x=0.98, y=0):\n",
    "    fig.add_annotation(\n",
    "        dict(xanchor=x_anchor, yanchor=y_anchor, x=x, y=y, text=f\"Sample Size: {len(df_new)}\", font=dict(size=16), ax=0, ay=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_percent_labels_for_hist(series : pd.Series, fig, horizontal=False, custom=False, custom_text_arr=None):\n",
    "    texts = []\n",
    "\n",
    "    if custom is True:\n",
    "        texts=custom_text_arr\n",
    "    else:\n",
    "        if horizontal is True:\n",
    "            texts=[format(len(hist['y'])/series.notna().sum() * 100, \".2f\") + \"%\" for hist in fig.data]\n",
    "        else:\n",
    "            texts=[format(len(hist['x'])/series.notna().sum() * 100, \".2f\") + \"%\" for hist in fig.data]\n",
    "    \n",
    "    for i, hist in enumerate(fig.data):\n",
    "        if horizontal is True:\n",
    "            hist[\"text\"] = f\"{len(hist['y'])} ({texts[i]})\"\n",
    "        else:\n",
    "            hist[\"text\"] = f\"{len(hist['x'])} ({texts[i]})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_dark_mode_plotly(fig):\n",
    "    fig.update_layout(paper_bgcolor='#2d3035', font=dict(color=\"#dcdcdc\"), plot_bgcolor='#2d3035',\n",
    "                      title_font=dict(color=\"#dfdfdf\")) \n",
    "    if fig.layout.updatemenus:\n",
    "        fig.layout.updatemenus[0].bgcolor=\"#ECECEC\"\n",
    "        fig.layout.updatemenus[0].font=dict(color=\"#000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_choice_survey(series: pd.Series, delimeter=\",\\s*\", column=\"substance\"):\n",
    "    \"\"\"\n",
    "        Process each answer of multiple choice answers as one row. \n",
    "        For example: a respondent answering 'a, b, c' will have his or her\n",
    "        answer processed as 'a' in one row, 'b' in the next, and 'c' in the next using\n",
    "        the default delimeter.   \n",
    "\n",
    "        TO-DO: Remove stopwords\n",
    "    \"\"\"\n",
    "    all_substances = []\n",
    "\n",
    "    # re.split does not appear to be greedy\n",
    "    for element in series:\n",
    "        split_array = re.split(delimeter, element)\n",
    "        assert \"\" not in split_array, f\"element: {split_array}\"\n",
    "        all_substances.extend(split_array)\n",
    "\n",
    "    df_copy = pd.DataFrame(np.expand_dims(all_substances, axis=1), columns=[column])\n",
    "    df_copy[column] = df_copy[column].str.strip()\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def get_percentages_for_multiple_choice_survey(series: pd.Series, a: pd.DataFrame):\n",
    "    df_copy = series.value_counts().reset_index()\n",
    "    df_copy[\"percentage\"] =  (df_copy[series.name] / len(a) * 100).round(2).astype(str) + \"%\"\n",
    "    df_copy.columns = [\"index\", \"count\", \"percentage\"]\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_regex(series: pd.Series):\n",
    "    series_lowered = series.str.lower()\n",
    "    return series_lowered.str.replace(r'[-./?!,\":;()\\']', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundancy(series: pd.Series, delimeter=\", \"):\n",
    "    \"\"\"\n",
    "        Remove redundancy from multiple choice data columns. Ex. \"Course 6, Course 5\" and \"Course 5, Course 6\" would both be\n",
    "        modified to look like \"Course 5, Course 6\". \n",
    "\n",
    "        remove_redundancy(pd.Series([\"5,6\", \"6,5\", \"6,6\", \"7,8\", \"8,7\"]), delimeter=\",\")\n",
    "\n",
    "        Out:\n",
    "        0    5,6\n",
    "        1    5,6\n",
    "        2    6,6\n",
    "        3    7,8\n",
    "        4    7,8\n",
    "        dtype: object\n",
    "    \"\"\"\n",
    "    series_remove_redundancy = series.str.split(delimeter).map(lambda x: delimeter.join(sorted(x)))\n",
    "    return series_remove_redundancy\n",
    "\n",
    "# remove_redundancy(pd.Series([\"5,6\", \"6,5\", \"6,6\", \"7,8\", \"8,7\"]), delimeter=\",\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_text(texts, char_limit=20):\n",
    "    def closest_next(text, idx):\n",
    "        ci = \" \"\n",
    "        return next(filter(lambda i: ci == text[i], range(idx, len(text))), len(text))\n",
    "\n",
    "\n",
    "    if type(texts) == str:\n",
    "        new_text = texts\n",
    "        for i in range(char_limit, len(texts) + 1, char_limit):\n",
    "            closest_i = closest_next(new_text, i)\n",
    "            new_text = new_text[0:closest_i] + \"<br>\" + new_text[closest_i+1:]\n",
    "\n",
    "        return new_text\n",
    "\n",
    "    if type(texts) == list:\n",
    "        list_of_new_texts = []\n",
    "        for text in texts:\n",
    "            new_text = text\n",
    "            for i in range(char_limit, len(text) + 1, char_limit):\n",
    "                closest_i = closest_next(new_text, i)\n",
    "                new_text = new_text[0:closest_i] + \"<br>\" + new_text[closest_i+1:]\n",
    "\n",
    "            list_of_new_texts.append(new_text)\n",
    "        \n",
    "        return list_of_new_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table and Bar Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_with_dropdown(a_new,\n",
    "                               columns,\n",
    "                               labels = None,\n",
    "                               reindex : list[bool] = None, # Example: [False, False]\n",
    "                               reindex_orders : list[list[str]] = None, # Example: [None, [\"A\", \"B\"]]. Reindex only second column \n",
    "                               headers=[\"Answer\", \"Number of Students\"],\n",
    "                               limit=None,\n",
    "                               base_height=208,\n",
    "                               include_percentage=True\n",
    "                               ):\n",
    "    \"\"\"\n",
    "        Count unique values for every column and display those counts in a table\n",
    "\n",
    "        ug157#    a = pd.DataFrame({\"a\" : [1, 1, 2, 2], \"b\" : [2, 2, 3, 3]})\n",
    "        ug157#    create_table_with_dropdown(a, [\"a\", \"b\"])\n",
    "\n",
    "        # Reindex Example:\n",
    "\n",
    "        ug157#    a = pd.DataFrame({\"a\" : [\"Male\", \"Female\", \"Female\", \"Female\"], \"b\" : [\"A\", \"D\", \"B\", \"C\"]})\n",
    "        ug157#    create_table_with_dropdown(a, [\"a\"    , \"b\"], reindex=[False, True], reindex_orders=[None, [\"A\", \"B\", \"C\", \"D\"]])\n",
    "        \n",
    "    \"\"\"\n",
    "    array_of_value_counts = []\n",
    "    if labels is None:\n",
    "        labels = columns\n",
    "\n",
    "    if reindex is None:\n",
    "        array_of_value_counts = [pd.DataFrame(a_new[column].value_counts()).reset_index() for column in columns]\n",
    "    else:\n",
    "        for i, column in enumerate(columns):\n",
    "            column_value_count = pd.DataFrame(a_new[column].value_counts())\n",
    "            if reindex[i] == True:\n",
    "                array_of_value_counts.append(\n",
    "                    column_value_count.reindex(reindex_orders[i]).reset_index()\n",
    "                )\n",
    "            else:\n",
    "                array_of_value_counts.append(\n",
    "                    column_value_count.reset_index()\n",
    "                )\n",
    "    \n",
    "\n",
    "    if limit:\n",
    "        array_of_value_counts = [value_count.head(limit) for value_count in array_of_value_counts]\n",
    "\n",
    "    if include_percentage:\n",
    "        for value_count in array_of_value_counts:\n",
    "            value_count[value_count.columns[1]] = value_count[value_count.columns[1]].astype(str) + \" (\" + \\\n",
    "                (value_count[value_count.columns[1]] / value_count[value_count.columns[1]].sum() * 100).round(2).astype(str) + \"%\" + \")\"\n",
    "\n",
    "    a_new_count_zero = array_of_value_counts[0]\n",
    "    fig = go.Figure(go.Table(header=dict(values=headers, fill_color=\"darkblue\", \n",
    "                                         font=dict(color=\"white\"), line_color=\"black\"), \n",
    "                             cells=dict(values=a_new_count_zero.T.values,\n",
    "                                        height=TABLE_CELL_HEIGHT_DEFAULT)\n",
    "                            )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            {   \n",
    "                **default_bar_dropdown_styling,\n",
    "                \"buttons\" : [{\n",
    "                    \"label\" : labels[i],\n",
    "                    \"method\": \"update\",\n",
    "                    \"args\" : [\n",
    "                        {\n",
    "                            \"cells\" : {\n",
    "                                \"values\" : array_of_value_counts[i].T.values, \n",
    "                                \"height\": TABLE_CELL_HEIGHT_DEFAULT,\n",
    "                            }\n",
    "                        },\n",
    "                        { \n",
    "                            \"title\" : labels[i],\n",
    "                            \"height\": calc_table_height(array_of_value_counts[i], base=base_height),\n",
    "                            \"cells_line_color\": \"black\",\n",
    "                            \"cells_fill_color\": \"#f5f5f5\"\n",
    "                        }\n",
    "                    ]\n",
    "                } for i, c in enumerate(columns)]\n",
    "            }\n",
    "        ],\n",
    "        paper_bgcolor=\"#FFFFFF\"\n",
    "    )\n",
    "\n",
    "    # Alway set height to the dropdown option with the most data, because it has the max height\n",
    "    fig.update_layout(title_text=labels[0], margin=dict(l=2, r=2),\n",
    "                      height=calc_table_height(max(array_of_value_counts, key=lambda x: x.shape[0]), base=base_height)\n",
    "    )\n",
    "    fig.layout.template[\"data\"][\"table\"][0][\"cells\"][\"fill\"][\"color\"] = \"white\"\n",
    "    fig.layout.template[\"data\"][\"table\"][0][\"cells\"][\"line\"][\"color\"] = \"darkslategray\"\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Example:\n",
    "# a = pd.DataFrame({\"a\" : [\"Male\", \"Female\", \"Female\", \"Female\"], \"b\" : [\"A\", \"D\", \"B\", \"C\"]})\n",
    "# fig = create_table_with_dropdown(a, [\"a\", \"b\"], reindex=[False, True], reindex_orders=[None, [\"A\", \"B\", \"C\", \"D\"]])\n",
    "# fig.show(renderer=\"notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure_with_dropdown(a_new, \n",
    "                                options=[\"What is your gender?\", \"Are you a domestic or international student?\"],\n",
    "                                filters=None,\n",
    "                                labels=None,\n",
    "                                showticklabels=[True, True],\n",
    "                                sort_traces=False,\n",
    "                                is_order_manually=False,\n",
    "                                manual_category_orders=None,\n",
    "                                horizontal=False,\n",
    "                                add_legend=True,\n",
    "                                textposition=\"outside\"):\n",
    "    \"\"\"\n",
    "        Create bar chart with dropdown selects. No Documentation on advanced usage with filters + labels.\n",
    "\n",
    "        # Create Bar Chart Dropdown\n",
    "        a = pd.DataFrame({\"a\" : [1, 1, 2, 2], \"b\" : [2, 2, 3, 3]})\n",
    "        create_figure_with_dropdown(a, [\"a\", \"b\"])\n",
    "\n",
    "        # Create Bar Chart with Sorted Counts (sort_traces=True). \n",
    "        # In this example, sort_traces would cause Female to come first (placed left) in the count plot instead of Male.\n",
    "        a = pd.DataFrame({\"a\" : [\"Male\", \"Female\", \"Female\"], \"b\" : [\"A\", \"A\", \"B\"]})\n",
    "        create_figure_with_dropdown(a, [\"a\", \"b\"], sort_traces=True)\n",
    "        \n",
    "    \"\"\"\n",
    "    fig = None\n",
    "    visibilities = []\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = options\n",
    "\n",
    "    unique_values_for_each_option = None\n",
    "    if filters is None:\n",
    "        unique_values_for_each_option = [a_new[option].unique() for option in options]\n",
    "    else:\n",
    "        unique_values_for_each_option = [a_new.loc[filters[i], option].unique() for i, option in enumerate(options)]\n",
    "        \n",
    "    # Add initial traces\n",
    "    length_per_option = [len(unique_values_for_one_option) for unique_values_for_one_option \n",
    "                            in unique_values_for_each_option]\n",
    "    \n",
    "    for i, unique_values_for_one_option in enumerate(unique_values_for_each_option):\n",
    "        for unique_value in unique_values_for_one_option:\n",
    "            unique_value_trace = None\n",
    "            if filters is not None and filters[i] is not None: \n",
    "                unique_value_trace = a_new.loc[filters[i] & (a_new[options[i]] == unique_value), \n",
    "                                                            options[i]]\n",
    "\n",
    "                if unique_value_trace.shape[0] == 0:\n",
    "                    continue\n",
    "            else:\n",
    "                unique_value_trace = a_new.loc[a_new[options[i]] == unique_value, \n",
    "                                                            options[i]]\n",
    "            \n",
    "            if horizontal is False:\n",
    "                fig.add_trace(go.Histogram(\n",
    "                                            x=unique_value_trace, \n",
    "                                            name=unique_value,\n",
    "                                            visible=True if i == 0 else False,\n",
    "                                            marker_autocolorscale=True,\n",
    "                                            text=f'{len(unique_value_trace)}' + \\\n",
    "                                                f' ({format(len(unique_value_trace)/a_new[options[i]].notna().sum() * 100, \".2f\")}%)',\n",
    "                                            textposition=textposition\n",
    "                                        ))\n",
    "            else:\n",
    "                fig.add_trace(go.Histogram(\n",
    "                            y=unique_value_trace, \n",
    "                            name=unique_value,\n",
    "                            visible=True if i == 0 else False,\n",
    "                            marker_autocolorscale=True,\n",
    "                            text=f'{len(unique_value_trace)}' + \\\n",
    "                                                f' ({format(len(unique_value_trace)/a_new[options[i]].notna().sum() * 100, \".2f\")}%)',\n",
    "                            textposition=textposition\n",
    "                        ))\n",
    "        \n",
    "\n",
    "    # i indexes the option being analyzed\n",
    "    for i, _ in enumerate(options):        \n",
    "        # Toggle visibility of traces per option\n",
    "        visibility = []\n",
    "        # j also indexes every option, but includes the lengths (number of unique values) for each option\n",
    "        for j, option_length in enumerate(length_per_option):\n",
    "            arr = [True] * option_length if i == j else [False] * option_length\n",
    "            visibility.extend(arr)\n",
    "        \n",
    "        visibilities.append(visibility)\n",
    "\n",
    "\n",
    "    ## Adjust axes properties for each option\n",
    "    args_arr = []\n",
    "\n",
    "    for i, option in enumerate(options):\n",
    "        \n",
    "        ## I totally forget why I use two indice orders\n",
    "        indice_order = a_new[option].value_counts().index.tolist() if filters is None else \\\n",
    "                       a_new.loc[filters[i], option].value_counts().index.tolist()\n",
    "        \n",
    "        indice_order_sorted = a_new[option].value_counts().sort_values().index.tolist() if filters is None else \\\n",
    "                       a_new.loc[filters[i], option].value_counts().sort_values().index.tolist()\n",
    "\n",
    "        if horizontal is False: \n",
    "            args_arr.append({\n",
    "                \"categoryorder\" : \"array\" if sort_traces is True or (is_order_manually is True \n",
    "                                                                and manual_category_orders[i] != None) else 'trace',\n",
    "                \"categoryarray\" :  manual_category_orders[i] if is_order_manually is True and manual_category_orders[i] != None else \n",
    "                                  indice_order if sort_traces is True else None, # only has effect when categoryorder is array\n",
    "                \"showticklabels\" : showticklabels[i]\n",
    "            })\n",
    "        else:\n",
    "            args_arr.append({\n",
    "                \"categoryorder\" : \"array\" if sort_traces is True or (is_order_manually is True \n",
    "                                                                and manual_category_orders[i] != None) else 'trace',\n",
    "                \"categoryarray\" :  manual_category_orders[i] if is_order_manually is True and manual_category_orders[i] != None else \n",
    "                                  indice_order_sorted if sort_traces is True else None, # only has effect when categoryorder is array\n",
    "                \"showticklabels\" : showticklabels[i]\n",
    "            })\n",
    "            \n",
    "\n",
    "    fig.update_traces(hovertemplate=\"<b>%{x}</b><br><i>Count:</i> %{y}\" if horizontal is False \n",
    "                                    else \"<b>%{y}</b><br><i>Count:</i> %{x}\", marker_autocolorscale=True)\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                **default_bar_dropdown_styling,\n",
    "                buttons=list([\n",
    "                    dict(label=labels[i],\n",
    "                         method=\"update\",\n",
    "                         args=[\n",
    "                            {\"visible\" : visibilities[i]},\n",
    "                            {\"title\" : labels[i],\n",
    "                             \"xaxis\" if horizontal is False else \"yaxis\" : args_arr[i]\n",
    "                             },\n",
    "                         ])\n",
    "                for i, option_name in enumerate(options)])\n",
    "            )\n",
    "        ],\n",
    "        paper_bgcolor=\"#D0E3F1\"\n",
    "    )\n",
    "\n",
    "    indice_order = a_new[options[0]].value_counts().index.tolist() if filters is None else \\\n",
    "                    a_new.loc[filters[0], options[0]].value_counts().index.tolist()\n",
    "    \n",
    "    indice_order_sorted = a_new[options[0]].value_counts().sort_values().index.tolist() if filters is None else \\\n",
    "                    a_new.loc[filters[0], options[0]].value_counts().sort_values().index.tolist()\n",
    "\n",
    "    if horizontal is not True:\n",
    "        if sort_traces:\n",
    "            fig.update_xaxes(categoryorder=\"array\", categoryarray=indice_order)\n",
    "        elif is_order_manually: \n",
    "            fig.update_xaxes(categoryorder=\"array\", categoryarray=manual_category_orders[0])\n",
    "        \n",
    "        fig.update_xaxes(showticklabels=showticklabels[0])\n",
    "    else:\n",
    "        if sort_traces:\n",
    "            fig.update_yaxes(categoryorder=\"array\", categoryarray=indice_order_sorted)\n",
    "        elif is_order_manually: \n",
    "            fig.update_yaxes(categoryorder=\"array\", categoryarray=manual_category_orders[0])  \n",
    "              \n",
    "        fig.update_yaxes(showticklabels=showticklabels[0])\n",
    "        \n",
    "    fig.update_layout(title_text=labels[0], margin=dict(l=2, r=2),\n",
    "                      dragmode=\"pan\", showlegend=False)\n",
    "    \n",
    "    if add_legend is True:            \n",
    "        fig.update_layout(legend=dict(yanchor=\"bottom\", xanchor=\"right\",\n",
    "                                x=1, y=0, orientation=\"v\"),\n",
    "                                showlegend=True)\n",
    "    return fig\n",
    "\n",
    "# a = pd.DataFrame({\"a\" : [\"Male\", \"Female\", \"Female\", \"Female\", \"Female\", \"Female\", \"Female\" \"Female\", \"Female\", \n",
    "#                           \"Female\", \"Female\", \"Male\", \"Male\", \"Male\", \"Male\"], \n",
    "#                     \"b\" : [\"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\", \"D\", \"D\", \"D\", \"D\", \"D\"]})\n",
    "# fig = create_figure_with_dropdown(a, [\"a\", \"b\"],\n",
    "#                             textposition=\"inside\", showticklabels=[False, False], sort_traces=True, horizontal=True)\n",
    "# fig\n",
    "\n",
    "# fig.update_layout(showlegend=True, \n",
    "#                   legend=dict(yanchor=\"top\", xanchor=\"center\",\n",
    "#                               orientation=\"h\",\n",
    "#                               x=0.5, y=-0.1))\n",
    "\n",
    "\n",
    "\n",
    "# a = pd.DataFrame({\"a\" : [\"Male\", \"Female\", \"Female\"], \"b\" : [\"A\", \"A\", \"B\"]})\n",
    "# create_figure_with_dropdown(a, [\"a\", \"b\"], sort_traces=False) # Default to False\n",
    "\n",
    "\n",
    "# a = pd.DataFrame({\"a\" : [\"He\", \"He\", \"He\", \"Loves\", \"Eating\", \"Strawberry\", \"Strawberry\", \"Wee\"],\n",
    "#                    \"b\" : [\"Sa\", \"Sa\", \"Sa\", \"Sa\", \"Sa\", \"Sa\", \"Ge\", \"Yo\"]})\n",
    "# create_figure_with_dropdown(a, options=[\"a\", \"b\"], is_wordcloud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(a_new,\n",
    "                 column,\n",
    "                 label=None,\n",
    "                 reindex=False,\n",
    "                 reindex_order : list[str] = None, \n",
    "                 headers=[\"Answer\", \"Number of Students\"],\n",
    "                 cell_height=25,\n",
    "                 header_height=25,\n",
    "                 base_height=208,\n",
    "                 include_percentage=True,\n",
    "                 limit=None):\n",
    "    '''\n",
    "        Returns a table of value counts\n",
    "    ''' \n",
    "    if label is None:\n",
    "        label = column\n",
    "\n",
    "    a_new_count = pd.DataFrame(a_new[column].value_counts()).reset_index() if reindex == False \\\n",
    "    else pd.DataFrame(a_new[column].value_counts()).reindex(reindex_order).reset_index()\n",
    "    \n",
    "    if limit:\n",
    "        a_new_count = a_new_count.head(limit)\n",
    "    \n",
    "    if include_percentage:\n",
    "            a_new_count[a_new_count.columns[1]] = a_new_count[a_new_count.columns[1]].astype(str) + \" (\" + \\\n",
    "                (a_new_count[a_new_count.columns[1]] / a_new[column].notna().sum() * 100).round(2).astype(str) + \"%\" + \")\"\n",
    "            \n",
    "    fig = go.Figure(go.Table(header=dict(values=headers, height=header_height, fill_color=\"black\", font=dict(color=\"white\", size=header_height/4), line_color=\"black\"), \n",
    "                             cells=dict(values=a_new_count.T.values, height=cell_height, font=dict(size=cell_height/3.5),\n",
    "                                        line_color=\"black\", fill_color=\"white\")))\n",
    "    fig.update_layout(margin=dict(l=2, r=2),\n",
    "                       height=calc_table_height(a_new_count, height_per_row=cell_height, base=base_height), title_text=label) \n",
    "    return fig\n",
    "\n",
    "# a = pd.DataFrame({\"a\" : [1, 1, 2, 2, 3, 3, 3]})\n",
    "\n",
    "# create_table(a, \"a\", reindex=True, reindex_order=a[\"a\"].value_counts().index.sort_values().tolist(), cell_height=65,\n",
    "#              header_height=65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rating_distributions(score_suffix, title_text, star_distrib : pd.Series):\n",
    "    fig_avg = go.Figure()\n",
    "    fig_avg.update_xaxes(visible=False)\n",
    "    fig_avg.update_yaxes(visible=False)\n",
    "    fig_avg.update_layout(paper_bgcolor=\"#D0E3F1\",\n",
    "                    height=300, margin=dict(l=0, r=0, t=60, b=60))\n",
    "    fig_avg.add_annotation(\n",
    "        dict(xref=\"paper\", yref=\"paper\", xanchor=\"center\", yanchor=\"middle\", x=0.5, y=0.5, ax=0, ay=0,\n",
    "        text=f\"{format(star_distrib.mean(), '.2f')} {score_suffix}\", font=dict(size=22))\n",
    "    )\n",
    "\n",
    "    fig_avg.add_annotation(\n",
    "        dict(xref=\"paper\", yref=\"paper\", xanchor=\"center\", yanchor=\"middle\", x=0.5, y=0.3, ax=0, ay=0,\n",
    "        text=\"Average\", font=dict(size=16))\n",
    "    )\n",
    "\n",
    "    fig_avg.add_annotation(\n",
    "        dict(xref=\"paper\", yref=\"paper\", xanchor=\"right\", yanchor=\"middle\", x=0.98, y=0.1, ax=0, ay=0,\n",
    "        text=f\"Sample Size: {len(star_distrib)}\", font=dict(size=12))\n",
    "    )\n",
    "\n",
    "    fig_avg.add_layout_image(\n",
    "        dict(source=\"./icons/star.png\", xref=\"paper\", yref=\"paper\", xanchor=\"center\", yanchor=\"middle\", x=0.35, y=0.525,\n",
    "        sizex=0.6, sizey=0.6, sizing=\"contain\")\n",
    "    )\n",
    "\n",
    "    star_distrib_str = star_distrib.astype(str)\n",
    "\n",
    "    fig = px.histogram(star_distrib_str, y=star_distrib_str.name, \n",
    "                  color=star_distrib_str.name)\n",
    "    fig.update_yaxes(title=\"Rating\", categoryorder=\"array\", \n",
    "                    categoryarray=\n",
    "                    star_distrib\n",
    "                    .sort_values()\n",
    "                    .astype(str).unique())\n",
    "    fig.update_traces(hovertemplate=less_cringe_hovertext_template[\"histogram_h\"][\"hovertemplate\"],\n",
    "                    marker=dict(color=\"rgb(253, 240, 54)\", \n",
    "                                line=dict(color=\"rgb(0, 0, 0)\", width=2)\n",
    "                    )\n",
    "    )\n",
    "\n",
    "    add_percent_labels_for_hist(star_distrib, fig, horizontal=True)\n",
    "\n",
    "    fig.update_layout(\n",
    "        bargap=0.5,\n",
    "        title=dict(\n",
    "            text=title_text,\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.93,\n",
    "            x=0.05,\n",
    "            font=dict(size=18)\n",
    "        ),\n",
    "        margin=dict(\n",
    "            t=100,\n",
    "            pad=7\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "    return fig_avg, fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordmap Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'ash': 2, 'bet': 3})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown file extension: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\harri\\miniconda3\\envs\\py310_notebook_env\\lib\\site-packages\\PIL\\Image.py:2408\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2408\u001b[0m     \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m EXTENSION[ext]\n\u001b[0;32m   2409\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 48\u001b[0m\n\u001b[0;32m     40\u001b[0m     fig\u001b[39m.\u001b[39mupdate_layout(xaxis\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mshowgrid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mshowticklabels\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mzeroline\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m},\n\u001b[0;32m     41\u001b[0m                         yaxis\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mshowgrid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mshowticklabels\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mzeroline\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m},\n\u001b[0;32m     42\u001b[0m                         margin\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(autoexpand\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, b\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, l\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, r\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, t\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), \n\u001b[0;32m     43\u001b[0m                         hovermode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m fig\n\u001b[1;32m---> 48\u001b[0m generate_word_map(pd\u001b[39m.\u001b[39;49mSeries([\u001b[39m\"\u001b[39;49m\u001b[39mash\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mash\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbet\u001b[39;49m\u001b[39m\"\u001b[39;49m]), is_frequency\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[26], line 30\u001b[0m, in \u001b[0;36mgenerate_word_map\u001b[1;34m(series, delimeter, file_path, width, height, max_words, is_frequency, collocations)\u001b[0m\n\u001b[0;32m     26\u001b[0m     freq_dict_reformatted \u001b[39m=\u001b[39m {phrase[\u001b[39m\"\u001b[39m\u001b[39mphrase\u001b[39m\u001b[39m\"\u001b[39m] : phrase[\u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m] \n\u001b[0;32m     27\u001b[0m                                      \u001b[39mfor\u001b[39;00m phrase \u001b[39min\u001b[39;00m freq_dict_records}\n\u001b[0;32m     29\u001b[0m     cloud\u001b[39m.\u001b[39mgenerate_from_frequencies(freq_dict_reformatted)\n\u001b[1;32m---> 30\u001b[0m cloud\u001b[39m.\u001b[39;49mto_file(file_path)\n",
      "File \u001b[1;32mc:\\Users\\harri\\miniconda3\\envs\\py310_notebook_env\\lib\\site-packages\\wordcloud\\wordcloud.py:726\u001b[0m, in \u001b[0;36mWordCloud.to_file\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Export to image file.\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \n\u001b[0;32m    715\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    725\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_image()\n\u001b[1;32m--> 726\u001b[0m img\u001b[39m.\u001b[39;49msave(filename, optimize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    727\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\harri\\miniconda3\\envs\\py310_notebook_env\\lib\\site-packages\\PIL\\Image.py:2411\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2409\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2410\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown file extension: \u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 2411\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   2413\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mupper() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m SAVE:\n\u001b[0;32m   2414\u001b[0m     init()\n",
      "\u001b[1;31mValueError\u001b[0m: unknown file extension: "
     ]
    }
   ],
   "source": [
    "# Saves a wordcloud into a specific file path and plot. Then plot the image\n",
    "def analyze_word_map_frequencies(series: pd.Series, columns=[\"language\", \"num_people_speaking\"],\n",
    "                                 delimiter=\",\\s*\") -> pd.DataFrame:\n",
    "    word_default_dict = defaultdict(int)\n",
    "    for _, values in series.items():\n",
    "        for word in re.split(delimiter, values):\n",
    "            word_default_dict[word] += 1\n",
    "\n",
    "    return pd.DataFrame(sorted(word_default_dict.items(), key=lambda x: x[1], reverse=True), \n",
    "            columns=columns)\n",
    "\n",
    "def generate_word_map(series : pd.Series, delimiter=\", \", file_path=None, width=1000, height=600, max_words=200, is_frequency=False,\n",
    "                      collocations=True, relative_scaling=0.75):\n",
    "    '''\n",
    "        Saves a wordcloud into a specific file path\n",
    "    '''\n",
    "    cloud = WordCloud(background_color=\"white\", max_words=max_words, mask=None, \n",
    "    stopwords=stopwords, width=width, height=height, colormap=\"tab20\",\n",
    "    min_font_size=8, max_font_size=125, relative_scaling=relative_scaling, collocations=collocations)\n",
    "    \n",
    "    if is_frequency is False:\n",
    "        cloud.generate(\" \".join(map(str, series)))\n",
    "    else:\n",
    "        freq_dict_records = analyze_word_map_frequencies(series, columns=[\"phrase\", \"count\"], \n",
    "                                                         delimiter=delimiter).to_dict(\"records\")\n",
    "        freq_dict_reformatted = {phrase[\"phrase\"] : phrase[\"count\"] \n",
    "                                         for phrase in freq_dict_records}\n",
    "    \n",
    "        cloud.generate_from_frequencies(freq_dict_reformatted)\n",
    "    cloud.to_file(file_path)\n",
    "\n",
    "\n",
    "\n",
    "def plot_word_map(file_path : str):\n",
    "    '''\n",
    "        file_path : path to wordcloud image    \n",
    "    '''\n",
    "    img = io.imread(file_path)\n",
    "    fig = px.imshow(img, binary_compression_level=6)\n",
    "    fig.update_layout(xaxis={'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
    "                        yaxis={'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
    "                        margin=dict(autoexpand=False, b=0, l=0, r=0, t=0), \n",
    "                        hovermode=False)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# generate_word_map(pd.Series([\"ash\", \"ash\", \"bet\", \"bet\", \"bet\"]), is_frequency=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map setup, see Location Profile for Usage\n",
    "def map_location_setup(location_series: pd.Series, data_coordinates: list[tuple]):\n",
    "    # geolocator = Nominatim(user_agent=\"app\")\n",
    "    # vancouver_location = geolocator.geocode(\"Vancouver, BC\")\n",
    "    # m = folium.Map(location=(vancouver_location.latitude, vancouver_location.longitude), tiles=\"cartodbpositron\",\n",
    "    #            zoom_start=2)\n",
    "    \n",
    "    unique_locs = location_series.unique().tolist()\n",
    "    num_per_unique_loc = location_series.value_counts()\n",
    "    a_location_coordinates = pd.DataFrame(\n",
    "        {\n",
    "    \"Coordinates\" : data_coordinates\n",
    "    },\n",
    "    index=unique_locs)\n",
    "    return pd.merge(a_location_coordinates, num_per_unique_loc, left_index=True, right_index=True)\n",
    "\n",
    "################################################# CAN'T MODULARIZE FOLIUM FOR SOME REASON ############33\n",
    "# def add_map_markers(a: pd.DataFrame, count_help_text,\n",
    "#                     icon_object=None):\n",
    "#     \"\"\"\n",
    "#         DataFrame format should look like \n",
    "\n",
    "#         | Coordinates | <Count_Column>       \n",
    "#         -------------------------------\n",
    "\n",
    "#         Index should be assigned to name of the location.\n",
    "#         Output from map_location_setup is an acceptable input\n",
    "#     \"\"\"\n",
    "#     m = create_map()\n",
    "#     if icon_object is None:\n",
    "#         icon_object = folium.Icon(icon=\"school\", color='lightblue', prefix='fa')\n",
    "\n",
    "#     for i in range(a.shape[0]):\n",
    "#         current_data = a.iloc[i]\n",
    "#         current_name = current_data.name\n",
    "#         number_per_name = current_data[a.columns[1]]\n",
    "#         html = f'''\n",
    "#         <div style=\"display: flex; justify-content: left; flex-direction: column;\">\n",
    "#             <div style=\"padding:0 10px 10px 0;color:grey\"><b>{current_name}</b></div>\n",
    "#             <div style=\"padding:0 10px 10px 0;font-size:40;font-weight:100;text-align:center\">{number_per_name}</div>\n",
    "#             <div style=\"text-align:center;padding:0 10px 0 0;\">{count_help_text}</div>\n",
    "#         </div>\n",
    "#         '''\n",
    "\n",
    "#         iframe = folium.IFrame(html=html, width=170, height=170)\n",
    "#         icon = icon_object\n",
    "#         popup = folium.Popup(iframe)\n",
    "#         folium.Marker(location=current_data[\"Coordinates\"], popup=popup, icon=icon\n",
    "#         ).add_to(m)\n",
    "\n",
    "#     return m\n",
    "    \n",
    "\n",
    "def create_map():\n",
    "    geolocator = Nominatim(user_agent=\"app\")\n",
    "    vancouver_location = geolocator.geocode(\"Vancouver, BC\")\n",
    "    m = folium.Map(location=(vancouver_location.latitude, vancouver_location.longitude), tiles='cartodbpositron',\n",
    "               control_scale=True, zoom_start=2)\n",
    "    # folium.LayerControl().add_to(m)\n",
    "    return m\n",
    "\n",
    "def get_figure_for_map(m: folium.Map, height=400):\n",
    "    f = folium.Figure(height=height)\n",
    "    m.add_to(f)\n",
    "    return f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sim_matrix(series: pd.Series) -> pd.DataFrame:\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    from similarity.longest_common_subsequence import LongestCommonSubsequence\n",
    "\n",
    "    LCS = LongestCommonSubsequence()\n",
    "    def compare_lcs(u, v):\n",
    "        min_length = min(len(u[0]), len(v[0]))\n",
    "        return min(-0.001, -(1 - (abs((LCS.distance(u[0], v[0]) - len(u[0]) - len(v[0])) / 2) / min_length)))\n",
    "        # return -((1 - cosine.similarity_profiles(cosine.get_profile(u[0]), cosine.get_profile(v[0]))) + levenshtein.distance(u[0], v[0]))\n",
    "\n",
    "    precomputed_similarity_matrix = squareform(pdist(np.expand_dims(series.unique(), axis=1), compare_lcs)) \n",
    "    df_precompute_sim_matrix = pd.DataFrame(\n",
    "        precomputed_similarity_matrix,\n",
    "        index=series.unique(),\n",
    "        columns=series.unique(),\n",
    "    )\n",
    "    return df_precompute_sim_matrix\n",
    "\n",
    "# Generate similarity matrix between every possible professor input\n",
    "# df_precompute_sim_matrix\n",
    "\n",
    "# Distribution of Similarity Matrix\n",
    "# px.histogram(df_precompute_sim_matrix[df_precompute_sim_matrix != 0].max(axis=1), title=\"Distribution of Largest Common Subsequence Metric\")\n",
    "\n",
    "# ### Removing Unique Professor Names\n",
    "# We apply this filter to try out best to not cluster professor names that were only entered in one way. \n",
    "# For example, if we all entered Hamid's name as Hamid, then there is no need to rewrite Hamid is any other way.\n",
    "\n",
    "# I only included inputs that have an LCS distance > -0.3, because I thought most inputs that have an LCS distance < -0.3 appeared to be unique professor names. I deducted this through trial and error. For each input, I found their most closely associated inputs with the LCS distance closest to 0 and put this information in a dataframe\n",
    "# def gather_closest_distances_for_each_word(row):\n",
    "#     closest_distances = row[row == row[row != 0].max()]\n",
    "#     best_matches_for_each_word = closest_distances.index.tolist()\n",
    "#     return [best_matches_for_each_word, row[row != 0].max()]\n",
    "\n",
    "\n",
    "# df_MAT = MAT.apply(gather_closest_distances_for_each_word, axis=1, result_type=\"expand\")\n",
    "# df_MAT\n",
    "\n",
    "# Per analysis above, We only include words iff they have at least one LCS distance < -0.3 with another word.\n",
    "\n",
    "def remove_unique(df_precompute_sim_matrix: pd.DataFrame, threshold=0.3): \n",
    "    df_precompute_sim_matrix = df_precompute_sim_matrix.loc[df_precompute_sim_matrix[(df_precompute_sim_matrix > -threshold) & (df_precompute_sim_matrix != 0)].any()]\n",
    "    df_precompute_sim_matrix = df_precompute_sim_matrix[df_precompute_sim_matrix.index]\n",
    "    return df_precompute_sim_matrix\n",
    "\n",
    "\n",
    "# Fit data to AP Cluster model\n",
    "def fit_data(df_precompute_sim_matrix: pd.DataFrame):\n",
    "    from sklearn.cluster import AffinityPropagation\n",
    "    ap_cluster = AffinityPropagation(random_state=5, affinity=\"precomputed\").fit(df_precompute_sim_matrix.to_numpy())\n",
    "    return ap_cluster\n",
    "    ### Automated Text Cleaning Using AP Clustering \n",
    "\n",
    "def generate_replacement_file(ap_cluster, df_precompute_sim_matrix: pd.DataFrame, output_file=None):\n",
    "    # ONLY RUN ONCE\n",
    "    # # ONLY RUN ONCE. This codeblock is used to memoize user prompt input.\n",
    "\n",
    "    replacement_tracker = [] # Keep track of user prompt input\n",
    "    for label in sorted(np.unique(ap_cluster.labels_)):\n",
    "        prompt_tuple = []\n",
    "        indices = df_precompute_sim_matrix.index[np.where(ap_cluster.labels_ == label)]\n",
    "        text = input(f\"Cluster: {indices}. Would you like to replace this cluster? (Y/N)\")\n",
    "        replacement_text = None\n",
    "        if text == \"Y\" or text == \"y\":\n",
    "            replacement_text = input(f\"Cluster: {indices}. Enter the text your would like to replace this cluster with:\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        prompt_tuple.append(text)\n",
    "        prompt_tuple.append(indices.tolist())\n",
    "        prompt_tuple.append(replacement_text)\n",
    "        replacement_tracker.append(prompt_tuple)\n",
    "\n",
    "    \n",
    "    '''\n",
    "        Write out replacement file. In the form of [Should_I_Replace_Cluster_With_Text, Replacement_Text]\n",
    "        [[\"Y\", \"Ashvin\"], [\"Y\", \"Bruno\"], [\"N\", None]]\n",
    "    '''\n",
    "    \n",
    "    json_obj = json.dumps(replacement_tracker, indent=4)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(json_obj)\n",
    "\n",
    "\n",
    "def execute_replacements(df, column=None, infile=None):\n",
    "    f = open(infile) \n",
    "    replacement_list = json.load(f)\n",
    "    f.close()\n",
    "    for text, indices, replacement_text in replacement_list:\n",
    "        if (text == \"Y\" or text == \"y\") and column is not None:\n",
    "            df[column].replace({index: replacement_text for index in indices}, inplace=True)\n",
    "        elif (text == \"Y\" or text == \"y\") and column is None:\n",
    "            df.replace({index: replacement_text for index in indices}, inplace=True)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fourth_year_opinions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
